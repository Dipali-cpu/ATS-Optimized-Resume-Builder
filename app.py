import streamlit as st
from datetime import datetime
import hashlib
import json
import re
from io import BytesIO
import base64
from pypdf import PdfReader



# All available projects
ALL_PROJECTS = [
    {
        "title": "Python Data Science Foundations Project",
        "description": "Built foundational data-science skills through Python by practicing variables, operators, loops, functions, exceptions, and object-oriented concepts. Explored data structures, logical problem-solving, and clean code habits. Strengthened analytical thinking, automation abilities, and readiness for real-world data workflows‚Äîlaying a solid base for advanced analytics, machine learning, and data-driven decision-making",
        "keywords": ["python", "data science", "programming", "analytics", "foundations", "oop"]
    },
    {
        "title": "Python Programming & Data Handling Project",
        "description": "Developed strong Python skills by working with lists, dictionaries, functions, loops, and file handling to process and analyze data efficiently. Practiced writing modular, error-resistant code and automating repetitive tasks. Strengthened logical thinking, data manipulation techniques, and foundational problem-solving abilities essential for data science and real-world analytical workflows.",
        "keywords": ["python", "data handling", "file handling", "automation", "data manipulation", "programming"]
    },
    {
        "title": "Advanced Python Data Processing Project",
        "description": "Enhanced data-science skills by using tuples, sets, comprehensions, and lambda functions to streamline data processing tasks. Built efficient, reusable code for organizing, transforming, and analyzing datasets. Strengthened logical reasoning, pattern recognition, and automation techniques essential for data cleaning, preprocessing, and building reliable analytical pipelines in real-world data-science projects",
        "keywords": ["python", "data processing", "lambda", "comprehensions", "preprocessing", "data cleaning"]
    },
    {
        "title": "Python Data Transformation & Automation Project",
        "description": "Applied advanced Python techniques including string manipulation, regular expressions, modules, and file operations to clean and structure raw data. Built automated scripts for extracting patterns, validating inputs, and improving data quality. Strengthened analytical thinking, precision, and workflow efficiency essential for data preprocessing, feature engineering, and real-world data-science tasks.",
        "keywords": ["python", "automation", "regex", "data transformation", "feature engineering", "etl"]
    },
    {
        "title": "Python Data Analysis & Visualization Foundations Project",
        "description": "Explored core data-science techniques using Python by practicing data organization, conditional logic, loops, and basic visualization. Applied structured problem-solving to clean, transform, and interpret datasets. Strengthened analytical thinking, automation skills, and the ability to build clear, functional scripts‚Äîforming a strong foundation for advanced analytics, machine learning, and real-world data workflows.",
        "keywords": ["python", "data analysis", "visualization", "analytics", "machine learning", "matplotlib"]
    },
    {
        "title": "Python Exploratory Data Processing & Automation Project",
        "description": "Strengthened data-science foundations by working with Python functions, loops, comprehensions, and file operations to clean, organize, and transform datasets. Practiced writing efficient, modular code for automating routine tasks and extracting meaningful patterns. Enhanced logical reasoning, problem-solving, and data-handling skills essential for exploratory analysis, preprocessing, and building reliable analytical workflows.",
        "keywords": ["python", "exploratory analysis", "automation", "data processing", "eda"]
    },
    {
        "title": "Python Data Cleaning & Workflow Optimization Project",
        "description": "Applied Python techniques such as functions, loops, conditional logic, and data structures to clean, filter, and organize datasets. Built efficient, reusable code to automate common tasks and improve processing speed. Strengthened analytical thinking, data-handling precision, and problem-solving abilities essential for preparing high-quality data and supporting accurate, real-world data-science workflows.",
        "keywords": ["python", "data cleaning", "optimization", "workflow", "automation"]
    },
    {
        "title": "Python Data Processing & Function Optimization Project",
        "description": "Developed strong data-science foundations by creating optimized functions, using loops, conditional logic, and list comprehensions to transform and analyze data. Practiced modular coding, error handling, and workflow automation. Strengthened problem-solving, pattern recognition, and data-handling efficiency‚Äîkey skills for building scalable analytical processes and preparing datasets for deeper statistical and machine-learning tasks.",
        "keywords": ["python", "optimization", "functions", "data processing", "scalability"]
    },
    {
        "title": "Statistical Foundations & Data Interpretation Project",
        "description": "Built core statistical skills by exploring measures of central tendency, variability, and data distribution. Applied Python to calculate, visualize, and interpret statistical patterns. Strengthened analytical thinking, numerical reasoning, and data-driven decision-making‚Äîkey abilities for understanding datasets, identifying trends, and supporting reliable insights in real-world data-science applications.",
        "keywords": ["statistics", "python", "data interpretation", "analytics", "patterns", "visualization"]
    },
    {
        "title": "Exploratory Statistics & Data Pattern Analysis Project",
        "description": "Strengthened statistical understanding by analyzing distributions, variability, and relationships within datasets. Used Python to compute descriptive statistics, visualize patterns, and interpret meaningful trends. Enhanced analytical reasoning, data-cleaning precision, and insight-generation skills essential for preparing datasets, validating assumptions, and supporting accurate decision-making in real-world data-science environments.",
        "keywords": ["statistics", "eda", "python", "data analysis", "patterns"]
    },
    {
        "title": "Probability Concepts & Statistical Insight Development Project",
        "description": "Explored foundational probability principles, including events, outcomes, and rule-based calculations. Applied Python to model scenarios, compute probabilities, and interpret results. Strengthened logical reasoning, analytical thinking, and quantitative problem-solving‚Äîbuilding essential skills for uncertainty analysis, predictive modeling, and data-driven decision-making in real-world data-science applications.",
        "keywords": ["probability", "statistics", "python", "modeling", "predictive analytics"]
    },
    {
        "title": "Probability Distributions & Data Interpretation Project",
        "description": "Studied key probability distributions and applied Python to compute, visualize, and interpret them. Gained practical experience analyzing randomness, variability, and real-world data behavior. Strengthened quantitative reasoning, statistical modeling skills, and the ability to draw meaningful insights‚Äîessential for building accurate predictive models and performing rigorous data-science analysis.",
        "keywords": ["probability", "distributions", "statistics", "python", "modeling", "predictive"]
    },
    {
        "title": "Statistical Inference & Data Variation Analysis Project",
        "description": "Explored statistical inference concepts using Python to analyze variability, sampling behavior, and confidence measures. Practiced interpreting patterns, validating assumptions, and understanding dataset uncertainty. Strengthened analytical reasoning, data-interpretation accuracy, and foundational statistical skills essential for drawing reliable conclusions and supporting evidence-based decision-making in data-science workflows.",
        "keywords": ["statistics", "inference", "python", "data validation", "analytics"]
    },
    {
        "title": "Hypothesis Testing & Statistical Decision-Making Project",
        "description": "Applied core hypothesis-testing techniques using Python to compare datasets, evaluate significance, and draw evidence-based conclusions. Explored p-values, test statistics, and error types to understand real-world uncertainty. Strengthened analytical judgment, statistical reasoning, and data-validation skills essential for accurate insights and scientifically grounded decision-making in data-science applications.",
        "keywords": ["hypothesis testing", "statistics", "python", "data validation", "analytics", "a/b testing"]
    },
    {
        "title": "Multivariable Statistical Testing & Comparative Analysis Project",
        "description": "Performed advanced statistical tests on three or more paired variables using Python to evaluate differences, relationships, and significance. Strengthened understanding of variance, dependency, and multivariable behavior. Enhanced analytical precision, data interpretation, and statistical reasoning‚Äîkey skills for modeling complex datasets and generating reliable insights in real-world data-science environments.",
        "keywords": ["statistics", "multivariable analysis", "python", "anova", "comparative analysis"]
    },
    {
        "title": "Generative AI Exploration & Model Interaction Project",
        "description": "Explored foundational generative AI concepts by interacting with Gemini models to generate text, analyze outputs, and understand prompt engineering. Strengthened skills in automation, creativity, and data interpretation. Gained practical experience leveraging AI tools for insights, content generation, and problem-solving‚Äîbuilding essential capabilities for modern data-science and AI-driven workflows.",
        "keywords": ["ai", "generative ai", "machine learning", "nlp", "prompt engineering", "llm"]
    },
    {
        "title": "Prompt Engineering & Generative AI Optimization Project",
        "description": "Developed effective prompt-engineering techniques to guide generative AI models in producing accurate, structured outputs. Explored instruction tuning, context design, and iterative refinement. Strengthened analytical reasoning, problem decomposition, and AI-assisted automation skills‚Äîkey abilities for enhancing model performance, improving data workflows, and leveraging generative systems in modern data-science environments",
        "keywords": ["prompt engineering", "ai", "generative ai", "optimization", "nlp", "llm"]
    },
    {
        "title": "SQL Database Management & Data Querying Project",
        "description": "Built strong foundational skills in database management by working with SQLite to create tables, insert records, and perform essential SQL queries. Strengthened understanding of structured data, relational design, and efficient data retrieval. Enhanced analytical thinking and data-handling accuracy‚Äîcore abilities for real-world data science, reporting, and data-driven decision-making",
        "keywords": ["sql", "database", "data management", "queries", "sqlite", "rdbms"]
    },
    {
        "title": "NoSQL Database Operations & Document Data Management Project",
        "description": "Gained hands-on experience with MongoDB by creating collections, inserting documents, and performing query operations. Strengthened understanding of unstructured data, schema flexibility, and efficient retrieval techniques. Enhanced analytical thinking, data organization, and database-handling skills essential for modern data-science workflows involving large-scale, semi-structured, or rapidly evolving datasets.",
        "keywords": ["nosql", "mongodb", "database", "data management", "document database", "json"]
    },
    {
        "title": "Data Visualization & Insight Communication Using Matplotlib",
        "description": "Created clear, meaningful visualizations using Matplotlib to analyze patterns, compare variables, and communicate insights effectively. Practiced plotting techniques, customization, and visual storytelling. Strengthened analytical reasoning, data interpretation, and presentation skills‚Äîcore abilities for transforming raw data into understandable narratives in real-world data-science and decision-making environments.",
        "keywords": ["matplotlib", "data visualization", "python", "analytics", "storytelling", "charts"]
    },
    {
        "title": "Advanced Data Visualization & Pattern Exploration with Matplotlib",
        "description": "Developed advanced visualization skills using Matplotlib to explore trends, compare relationships, and present complex insights clearly. Practiced customizing plots, handling datasets, and choosing effective visual formats. Strengthened analytical interpretation, storytelling abilities, and data-driven communication‚Äîkey capabilities for delivering meaningful insights in professional data-science and business decision-making environments.",
        "keywords": ["matplotlib", "visualization", "analytics", "python", "data science", "dashboards"]
    },
    {
        "title": "Data Manipulation & Analysis Using Pandas",
        "description": "Built strong data-science skills by using Pandas to clean, filter, transform, and analyze structured datasets. Practiced handling DataFrames, performing aggregations, managing missing values, and deriving insights. Strengthened analytical thinking, data-wrangling efficiency, and problem-solving‚Äîfoundational abilities for preparing high-quality data and supporting accurate, real-world analytical and machine-learning workflows.",
        "keywords": ["pandas", "python", "data analysis", "data wrangling", "dataframes", "etl"]
    },
    {
        "title": "Numerical Computing & Array Operations Using NumPy",
        "description": "Developed strong numerical analysis skills by working with NumPy arrays, vectorized operations, indexing, and mathematical functions. Practiced efficient data handling, transformations, and computations essential for large datasets. Strengthened analytical reasoning, performance-focused coding, and foundational quantitative abilities crucial for machine learning, scientific computing, and real-world data-science applications.",
        "keywords": ["numpy", "python", "numerical computing", "arrays", "machine learning", "linear algebra"]
    },
    {
        "title": "Data Import, Export & File Handling Automation Project",
        "description": "Strengthened data-engineering skills by reading, writing, and managing files in multiple formats using Python. Automated data-loading workflows, cleaned raw inputs, and organized datasets for analysis. Enhanced accuracy, efficiency, and problem-solving abilities‚Äîcore capabilities for building reliable data pipelines and supporting real-world data-science and machine-learning processes.",
        "keywords": ["python", "file handling", "automation", "data engineering", "etl", "pipelines"]
    },
    {
        "title": "Machine Learning Model Development & Predictive Analysis Project",
        "description": "Built and evaluated machine-learning models using Python to understand classification, regression, and performance metrics. practiced data preprocessing, feature selection, and model tuning to improve accuracy. Strengthened analytical reasoning, algorithmic understanding, and predictive insight‚Äîkey skills for solving real-world problems and delivering data-driven solutions in professional data-science environments.",
        "keywords": ["machine learning", "python", "predictive modeling", "classification", "regression", "sklearn"]
    },
    {
        "title": "Advanced Machine Learning Techniques & Model Optimization Project",
        "description": "Explored advanced machine-learning concepts by building and tuning models, evaluating performance, and applying preprocessing techniques. Strengthened skills in feature engineering, algorithm selection, and interpreting model outcomes. Enhanced analytical decision-making, predictive accuracy, and problem-solving abilities‚Äîcrucial for developing reliable, high-performing machine-learning solutions in real-world data-science environments",
        "keywords": ["machine learning", "optimization", "feature engineering", "python", "modeling", "hyperparameter tuning"]
    },
    {
        "title": "Model Evaluation & Performance Improvement in Machine Learning",
        "description": "Practiced evaluating machine-learning models using metrics, validation techniques, and error analysis to improve predictive performance. Applied preprocessing, feature scaling, and algorithm comparison to understand model behavior. Strengthened analytical reasoning, optimization skills, and data-driven decision-making‚Äîkey abilities for building accurate, reliable machine-learning systems in real-world data-science applications.",
        "keywords": ["machine learning", "model evaluation", "optimization", "python", "metrics", "cross-validation"]
    }
]

# Main application
st.set_page_config(page_title="ATS Resume Builder", page_icon="üìÑ", layout="wide")

st.title("üìÑ ATS-Optimized Resume Builder v4.0")
st.markdown("Smart resume builder with AI-powered project selection and interview preparation")

# Initialize session state
if 'resume_data' not in st.session_state:
    st.session_state.resume_data = {}
if 'photo_data' not in st.session_state:
    st.session_state.photo_data = None
if 'cv_text' not in st.session_state:
    st.session_state.cv_text = ""
if 'selected_projects' not in st.session_state:
    st.session_state.selected_projects = []
if 'job_description' not in st.session_state:
    st.session_state.job_description = ""

# Create tabs
tab1, tab2, tab3, tab4 = st.tabs(["üìù Fill Information", "üéØ ATS Analysis & Smart Projects", "‚ùì Interview Prep", "üëÅÔ∏è Preview & Download"])

with tab1:
    st.header("üìÑ Upload Existing CV (Optional)")
    st.markdown("Upload your existing CV to **auto-fill the entire form** and extract all information")
    
    uploaded_cv = st.file_uploader("Upload CV (PDF, DOCX, TXT)", type=['pdf', 'docx', 'txt'], key="cv_uploader")
    
    if uploaded_cv is not None:
        try:
            if uploaded_cv.type == "text/plain":
                st.session_state.cv_text = uploaded_cv.read().decode('utf-8')
                st.success("‚úÖ CV uploaded successfully!")
            elif uploaded_cv.type == "application/pdf":
                try:
                    # Try pypdf first (newer)
                    try:
                        from pypdf import PdfReader
                        pdf_reader = PdfReader(uploaded_cv)
                        st.session_state.cv_text = ""
                        for page in pdf_reader.pages:
                            st.session_state.cv_text += page.extract_text() + "\n"
                        st.success("‚úÖ PDF uploaded successfully!")
                    except ImportError:
                        # Fallback to PyPDF2 (older)
                        import PyPDF2
                        pdf_reader = PyPDF2.PdfReader(uploaded_cv)
                        st.session_state.cv_text = ""
                        for page in pdf_reader.pages:
                            st.session_state.cv_text += page.extract_text() + "\n"
                        st.success("‚úÖ PDF uploaded successfully!")
                except Exception as pdf_error:
                    st.error(f"PDF reading error: {str(pdf_error)}")
                    st.warning("üí° To fix: Run `pip install pypdf` or `pip install PyPDF2` in terminal")
            elif uploaded_cv.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                try:
                    import docx
                    doc = docx.Document(uploaded_cv)
                    st.session_state.cv_text = "\n".join([para.text for para in doc.paragraphs])
                    st.success("‚úÖ DOCX uploaded successfully!")
                except Exception as docx_error:
                    st.error(f"DOCX reading error: {str(docx_error)}")
                    st.warning("üí° To fix: Run `pip install python-docx` in terminal")
            
            if st.session_state.cv_text:
                with st.expander("View extracted text"):
                    st.text_area("Extracted CV Text", st.session_state.cv_text, height=200, disabled=True)
                
                # Auto-fill button
                st.markdown("---")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ü§ñ Auto-Fill Form from CV", type="primary", use_container_width=True):
                        with st.spinner("Analyzing CV and extracting information..."):
                            cv_text = st.session_state.cv_text
                            cv_lower = cv_text.lower()
                            lines = [line.strip() for line in cv_text.split('\n') if line.strip()]
                            
                            # Initialize extracted data
                            extracted = {}
                            
                            # === IMPROVED EMAIL EXTRACTION ===
                            email_patterns = [
                                r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
                                r'email[:\s]+([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,})',
                                r'e-mail[:\s]+([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,})'
                            ]
                            for pattern in email_patterns:
                                email_match = re.search(pattern, cv_text, re.IGNORECASE)
                                if email_match:
                                    extracted['email'] = email_match.group() if '@' in email_match.group() else email_match.group(1)
                                    break
                            
                            # === IMPROVED PHONE EXTRACTION ===
                            phone_patterns = [
                                r'\+?\d{1,3}[-.\s]?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}',
                                r'\+?\d{10,13}',
                                r'(?:phone|mobile|cell|tel|contact)[:\s]+([+\d\s\-\(\)]{10,})',
                                r'\d{3}[-.\s]\d{3}[-.\s]\d{4}',
                                r'\(\d{3}\)\s*\d{3}[-.\s]\d{4}'
                            ]
                            for pattern in phone_patterns:
                                phone_match = re.search(pattern, cv_text, re.IGNORECASE)
                                if phone_match:
                                    phone = phone_match.group() if phone_match.groups() == () else phone_match.group(1)
                                    phone = re.sub(r'(?:phone|mobile|cell|tel|contact)[:\s]+', '', phone, flags=re.IGNORECASE)
                                    extracted['phone'] = phone.strip()
                                    break
                            
                            # === IMPROVED NAME EXTRACTION ===
                            name_found = False
                            
                            # Method 1: Look for "Name:" label
                            for line in lines[:15]:
                                if re.match(r'^(?:name|candidate|applicant)[:\s]+(.+)', line, re.IGNORECASE):
                                    match = re.match(r'^(?:name|candidate|applicant)[:\s]+(.+)', line, re.IGNORECASE)
                                    extracted['name'] = match.group(1).strip()
                                    name_found = True
                                    break
                            
                            # Method 2: First non-empty line that looks like a name (2-4 words, no numbers, no email)
                            if not name_found:
                                for line in lines[:10]:
                                    words = line.split()
                                    if (2 <= len(words) <= 4 and 
                                        not '@' in line and 
                                        not any(char.isdigit() for char in line) and
                                        not any(kw in line.lower() for kw in ['resume', 'cv', 'curriculum', 'profile', 'summary']) and
                                        len(line) < 50):
                                        extracted['name'] = line.strip()
                                        name_found = True
                                        break
                            
                            # === IMPROVED LOCATION EXTRACTION ===
                            location_patterns = [
                                r'(?:location|address|city|residence|based in)[:\s]+(.+?)(?:\n|$)',
                                r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?,\s*[A-Z]{2,})',  # City, STATE
                                r'([A-Z][a-z]+,\s*[A-Z][a-z]+(?:,\s*\d{5})?)'  # City, State, ZIP
                            ]
                            for pattern in location_patterns:
                                loc_match = re.search(pattern, cv_text, re.IGNORECASE)
                                if loc_match:
                                    location = loc_match.group(1) if loc_match.groups() else loc_match.group()
                                    location = re.sub(r'(?:location|address|city|residence|based in)[:\s]+', '', location, flags=re.IGNORECASE)
                                    extracted['location'] = location.strip()
                                    break
                            
                            # === IMPROVED LINKEDIN EXTRACTION ===
                            linkedin_patterns = [
                                r'(?:linkedin\.com/in/[\w-]+)',
                                r'(?:www\.)?linkedin\.com/in/([\w-]+)',
                                r'(?:linkedin)[:\s]+(linkedin\.com/in/[\w-]+)',
                                r'(?:linkedin)[:\s]+(.+?)(?:\n|$)'
                            ]
                            for pattern in linkedin_patterns:
                                li_match = re.search(pattern, cv_text, re.IGNORECASE)
                                if li_match:
                                    linkedin = li_match.group()
                                    if 'linkedin.com' in linkedin.lower():
                                        if not linkedin.startswith('http'):
                                            linkedin = 'https://' + linkedin
                                        extracted['linkedin'] = linkedin.strip()
                                        break
                            
                            # === IMPROVED GITHUB EXTRACTION ===
                            github_patterns = [
                                r'(?:github\.com/[\w-]+)',
                                r'(?:www\.)?github\.com/([\w-]+)',
                                r'(?:github)[:\s]+(github\.com/[\w-]+)',
                                r'(?:github)[:\s]+(.+?)(?:\n|$)'
                            ]
                            for pattern in github_patterns:
                                gh_match = re.search(pattern, cv_text, re.IGNORECASE)
                                if gh_match:
                                    github = gh_match.group()
                                    if 'github.com' in github.lower():
                                        if not github.startswith('http'):
                                            github = 'https://' + github
                                        extracted['github'] = github.strip()
                                        break
                            
                            # === IMPROVED SKILLS EXTRACTION ===
                            skill_section = ""
                            in_skills = False
                            end_markers = ['experience', 'education', 'project', 'certification', 'work', 'employment', 'career']
                            
                            for i, line in enumerate(lines):
                                line_lower = line.lower()
                                
                                # Start capturing when we find skills section
                                if any(kw in line_lower for kw in ['skill', 'technical', 'technologies', 'competencies', 'expertise']):
                                    in_skills = True
                                    continue
                                
                                # Stop when we hit another section
                                if in_skills and any(marker in line_lower for marker in end_markers):
                                    break
                                
                                # Capture skill lines
                                if in_skills:
                                    skill_section += line + ", "
                                    if i > 100:
                                        break
                            
                            if skill_section:
                                # Clean skills
                                skills = re.sub(r'[‚Ä¢\-\*\|\[\]{}]', '', skill_section)
                                skills = re.sub(r'\s+', ' ', skills)
                                
                                # Split by common delimiters
                                skill_list = []
                                for delim in [',', '|', '‚Ä¢', ';']:
                                    if delim in skills:
                                        skill_list = [s.strip() for s in skills.split(delim) if s.strip() and len(s.strip()) > 1]
                                        break
                                
                                if not skill_list:
                                    skill_list = skills.split()
                                
                                # Remove duplicates and clean
                                skill_list = list(dict.fromkeys([s.strip() for s in skill_list if len(s.strip()) > 2]))
                                extracted['skills'] = ', '.join(skill_list[:20])  # Limit to 20 skills
                            
                            # If no skills found, look for common tech terms
                            if not extracted.get('skills'):
                                tech_keywords = ['python', 'java', 'javascript', 'sql', 'react', 'node', 'aws', 
                                               'docker', 'kubernetes', 'machine learning', 'data science', 'pandas', 
                                               'numpy', 'tensorflow', 'pytorch', 'html', 'css', 'git']
                                found_skills = [kw for kw in tech_keywords if kw in cv_lower]
                                if found_skills:
                                    extracted['skills'] = ', '.join(found_skills)
                            
                            # === IMPROVED SUMMARY EXTRACTION ===
                            summary_found = False
                            summary_keywords = ['summary', 'profile', 'objective', 'about', 'overview', 'introduction']
                            
                            for i, line in enumerate(lines):
                                if any(kw in line.lower() for kw in summary_keywords) and len(line) < 50:
                                    # Get next 2-5 lines
                                    summary_lines = []
                                    for j in range(i+1, min(i+6, len(lines))):
                                        if any(end in lines[j].lower() for end in ['experience', 'education', 'skill', 'project']):
                                            break
                                        summary_lines.append(lines[j])
                                    
                                    if summary_lines:
                                        extracted['summary'] = ' '.join(summary_lines)[:400]
                                        summary_found = True
                                        break
                            
                            # If no summary found, create from first paragraph
                            if not summary_found:
                                first_para = []
                                for line in lines[3:15]:  # Skip name/contact info
                                    if len(line) > 30 and not any(kw in line.lower() for kw in ['email', 'phone', 'linkedin', 'github']):
                                        first_para.append(line)
                                        if len(' '.join(first_para)) > 200:
                                            break
                                
                                if first_para:
                                    extracted['summary'] = ' '.join(first_para)[:400]
                            
                            # === UPDATE SESSION STATE ===
                            if extracted.get('email'):
                                st.session_state['auto_email'] = extracted['email']
                            if extracted.get('phone'):
                                st.session_state['auto_phone'] = extracted['phone']
                            if extracted.get('name'):
                                st.session_state['auto_name'] = extracted['name']
                            if extracted.get('location'):
                                st.session_state['auto_location'] = extracted['location']
                            if extracted.get('linkedin'):
                                st.session_state['auto_linkedin'] = extracted['linkedin']
                            if extracted.get('github'):
                                st.session_state['auto_github'] = extracted['github']
                            if extracted.get('skills'):
                                st.session_state['auto_skills'] = extracted['skills']
                            if extracted.get('summary'):
                                st.session_state['auto_summary'] = extracted['summary']
                            
                            # Show what was extracted
                            st.success("‚úÖ Form auto-filled successfully!")
                            
                            with st.expander("üìä Extracted Information Preview", expanded=True):
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.write("**Name:**", extracted.get('name', '‚ùå Not found'))
                                    st.write("**Email:**", extracted.get('email', '‚ùå Not found'))
                                    st.write("**Phone:**", extracted.get('phone', '‚ùå Not found'))
                                    st.write("**Location:**", extracted.get('location', '‚ùå Not found'))
                                with col2:
                                    st.write("**LinkedIn:**", extracted.get('linkedin', '‚ùå Not found'))
                                    st.write("**GitHub:**", extracted.get('github', '‚ùå Not found'))
                                    st.write("**Skills Count:**", len(extracted.get('skills', '').split(',')) if extracted.get('skills') else 0)
                                    st.write("**Summary Length:**", len(extracted.get('summary', '')) if extracted.get('summary') else 0)
                            
                            st.info("üí° Scroll down to review all fields. Edit anything that needs correction before saving!")
                            st.rerun()
                
                with col2:
                    if st.button("üîÑ Clear Auto-Fill Data", use_container_width=True):
                        keys_to_clear = ['auto_name', 'auto_email', 'auto_phone', 'auto_location', 
                                        'auto_linkedin', 'auto_github', 'auto_skills', 'auto_summary']
                        for key in keys_to_clear:
                            if key in st.session_state:
                                del st.session_state[key]
                        st.success("‚úÖ Auto-fill data cleared!")
                        st.rerun()
        except Exception as e:
            st.error(f"Error reading file: {str(e)}")
            st.info("Supported formats: PDF, DOCX, TXT")
    
    st.header("Personal Information")
    col1, col2 = st.columns([2, 1])
    
    with col1:
        full_name = st.text_input("Full Name*", key="name", value=st.session_state.get('auto_name', ''))
        email = st.text_input("Email*", key="email", value=st.session_state.get('auto_email', ''))
        phone = st.text_input("Phone Number*", key="phone", value=st.session_state.get('auto_phone', ''))
        location = st.text_input("Location (City, State)", key="location", value=st.session_state.get('auto_location', ''))
        
    with col2:
        st.markdown("#### Upload Photo")
        photo = st.file_uploader("Profile Photo (Optional)", type=['jpg', 'jpeg', 'png'])
        if photo:
            st.session_state.photo_data = photo.read()
            st.image(st.session_state.photo_data, width=150)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        linkedin = st.text_input("LinkedIn URL", key="linkedin", value=st.session_state.get('auto_linkedin', ''))
    with col2:
        github = st.text_input("GitHub URL", key="github", value=st.session_state.get('auto_github', ''))
    with col3:
        portfolio = st.text_input("Portfolio/Website", key="portfolio")
    
    st.header("Professional Summary")
    
    if st.session_state.cv_text:
        if st.button("ü§ñ Auto-Generate Summary from CV"):
            with st.spinner("Generating professional summary..."):
                lines = st.session_state.cv_text.split('\n')
                summary_keywords = ['summary', 'profile', 'objective', 'about']
                extracted_summary = ""
                
                for i, line in enumerate(lines):
                    if any(keyword in line.lower() for keyword in summary_keywords):
                        extracted_summary = ' '.join(lines[i+1:i+4])
                        break
                
                if extracted_summary:
                    st.session_state['summary_text'] = extracted_summary[:300]
                else:
                    st.session_state['summary_text'] = "Experienced professional with strong technical and analytical skills."
                st.success("‚úÖ Summary generated! Edit it below.")
                st.rerun()
    
    summary = st.text_area("Professional Summary (2-3 sentences)*", 
                          value=st.session_state.get('summary_text', ''),
                          height=100, key="summary")
    
    st.header("Work Experience")
    num_experiences = st.number_input("Number of work experiences", min_value=0, max_value=10, value=1)
    
    experiences = []
    for i in range(num_experiences):
        st.subheader(f"Experience {i+1}")
        col1, col2 = st.columns(2)
        with col1:
            job_title = st.text_input(f"Job Title*", key=f"job_title_{i}")
            company = st.text_input(f"Company Name*", key=f"company_{i}")
        with col2:
            start_date = st.text_input(f"Start Date (e.g., Jan 2020)*", key=f"start_{i}")
            end_date = st.text_input(f"End Date (e.g., Dec 2022 or Present)*", key=f"end_{i}")
        
        responsibilities = st.text_area(f"Key Responsibilities & Achievements (one per line)*", 
                                       height=100, key=f"resp_{i}")
        
        if job_title and company and start_date and end_date:
            experiences.append({
                "title": job_title,
                "company": company,
                "start": start_date,
                "end": end_date,
                "responsibilities": responsibilities.split('\n') if responsibilities else []
            })
    
    st.header("Education")
    num_education = st.number_input("Number of educational qualifications", min_value=1, max_value=5, value=1)
    
    education = []
    for i in range(num_education):
        st.subheader(f"Education {i+1}")
        col1, col2 = st.columns(2)
        with col1:
            degree = st.text_input(f"Degree*", key=f"degree_{i}")
            institution = st.text_input(f"Institution Name*", key=f"institution_{i}")
        with col2:
            edu_start = st.text_input(f"Start Year*", key=f"edu_start_{i}")
            edu_end = st.text_input(f"End Year (or Expected)*", key=f"edu_end_{i}")
        
        gpa = st.text_input(f"GPA (optional)", key=f"gpa_{i}")
        
        if degree and institution and edu_start and edu_end:
            edu_entry = {
                "degree": degree,
                "institution": institution,
                "start": edu_start,
                "end": edu_end
            }
            if gpa:
                edu_entry["gpa"] = gpa
            education.append(edu_entry)
    
    st.header("Technical Skills")
    st.markdown("Enter your technical skills separated by commas")
    technical_skills = st.text_area("Technical Skills*", height=80, key="tech_skills",
                                   value=st.session_state.get('auto_skills', ''),
                                   placeholder="Python, JavaScript, SQL, Machine Learning, AWS, etc.")
    
    st.header("Certifications")
    st.info("üìå Fixed Certification: Bhartiya Vidya Bhavans Sardar Patel Institute Of Technology - Professional Certificate in Artificial Intelligence")
    
    additional_certs = st.text_area("Additional Certifications (one per line, optional)", height=80, key="add_certs")
    
    if st.button("üíæ Save Information", type="primary"):
        cert_fixed = "Bhartiya Vidya Bhavans Sardar Patel Institute Of Technology - Professional Certificate in Artificial Intelligence"
        all_certs = [cert_fixed]
        if additional_certs:
            all_certs.extend([c.strip() for c in additional_certs.split('\n') if c.strip()])
        
        st.session_state.resume_data = {
            "name": full_name,
            "email": email,
            "phone": phone,
            "linkedin": linkedin,
            "github": github,
            "portfolio": portfolio,
            "location": location,
            "summary": summary,
            "experiences": experiences,
            "education": education,
            "technical_skills": [s.strip() for s in technical_skills.split(',') if s.strip()],
            "projects": st.session_state.selected_projects,
            "certifications": all_certs,
            "photo": st.session_state.photo_data
        }
        st.success("‚úÖ Information saved! Proceed to ATS Analysis tab.")

with tab2:
    st.header("üéØ Advanced ATS Analysis & Smart Project Selection")
    
    if st.session_state.resume_data:
        st.markdown("### Job Description")
        job_description = st.text_area("Paste the complete job description:", 
                                       height=250, key="job_desc_input",
                                       value=st.session_state.job_description)
        
        if st.button("üìä Analyze Resume & Select Best Projects", type="primary"):
            if job_description:
                st.session_state.job_description = job_description
                
                with st.spinner("Running AI-powered analysis..."):
                    data = st.session_state.resume_data
                    
                    # Prepare resume text
                    resume_text = {
                        'summary': data.get('summary', '').lower(),
                        'experience': ' '.join([f"{exp.get('title', '')} {exp.get('company', '')} {' '.join(exp.get('responsibilities', []))}" 
                                               for exp in data.get('experiences', [])]).lower(),
                        'education': ' '.join([f"{edu.get('degree', '')} {edu.get('institution', '')}" 
                                              for edu in data.get('education', [])]).lower(),
                        'skills': ' '.join(data.get('technical_skills', [])).lower()
                    }
                    
                    full_resume_text = ' '.join(resume_text.values())
                    job_desc_lower = job_description.lower()
                    
                    # Stop words
                    stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'a', 'an', 
                                 'is', 'are', 'was', 'were', 'been', 'be', 'have', 'has', 'had', 'do', 'does', 'did',
                                 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that',
                                 'these', 'those', 'from', 'into', 'through', 'during', 'before', 'after', 'above',
                                 'below', 'between', 'under', 'again', 'further', 'then', 'once', 'here', 'there',
                                 'when', 'where', 'why', 'how', 'all', 'both', 'each', 'few', 'more', 'most', 'other',
                                 'some', 'such', 'only', 'own', 'same', 'than', 'too', 'very', 'just', 'about'}
                    
                    # Extract keywords
                    job_words = re.findall(r'\b[a-z]+\b', job_desc_lower)
                    job_keywords = [w for w in job_words if len(w) > 3 and w not in stop_words]
                    
                    # Extract multi-word phrases (bigrams and trigrams)
                    job_phrases = []
                    words = job_desc_lower.split()
                    
                    # Extract 2-word phrases (bigrams)
                    for i in range(len(words) - 1):
                        if len(words[i]) > 2 and len(words[i+1]) > 2:
                            phrase = f"{words[i]} {words[i+1]}"
                            if not any(stop in phrase for stop in ['the ', ' the', 'and ', ' and', 'or ', ' or']):
                                job_phrases.append(phrase)
                    
                    # Extract 3-word phrases (trigrams) for better matching
                    for i in range(len(words) - 2):
                        if len(words[i]) > 2 and len(words[i+1]) > 2 and len(words[i+2]) > 2:
                            phrase = f"{words[i]} {words[i+1]} {words[i+2]}"
                            if not any(stop in phrase for stop in ['the ', ' the', 'and ', ' and', 'or ', ' or', 'a ', ' a ']):
                                job_phrases.append(phrase)
                    
                    # Tech skills list (EXPANDED)
                    tech_skills = ['python', 'java', 'javascript', 'react', 'angular', 'vue', 'node', 'sql', 
                                  'mongodb', 'aws', 'azure', 'gcp', 'google cloud', 'docker', 'kubernetes', 'git', 'agile', 'scrum',
                                  'machine learning', 'artificial intelligence', 'data science', 'tensorflow',
                                  'pytorch', 'scikit-learn', 'sklearn', 'pandas', 'numpy', 'html', 'css', 'api', 'rest',
                                  'graphql', 'typescript', 'c++', 'c#', 'golang', 'rust', 'swift', 'kotlin', 'deep learning',
                                  'nlp', 'natural language processing', 'computer vision', 'data analysis', 'statistical analysis', 
                                  'matplotlib', 'seaborn', 'tableau', 'power bi', 'powerbi', 'excel', 'spark', 'hadoop', 
                                  'kafka', 'redis', 'postgresql', 'mysql', 'oracle', 'nosql', 'etl', 'data warehouse',
                                  'data engineering', 'devops', 'ci/cd', 'jenkins', 'gitlab', 'github', 'bitbucket',
                                  'linux', 'unix', 'bash', 'shell scripting', 'microservices', 'serverless', 'lambda',
                                  'ec2', 's3', 'rds', 'dynamodb', 'cloudformation', 'terraform', 'ansible', 'chef', 'puppet',
                                  'jira', 'confluence', 'slack', 'trello', 'asana', 'django', 'flask', 'fastapi', 'spring',
                                  'express', 'nest', 'next', 'vue', 'svelte', 'webpack', 'babel', 'eslint', 'jest', 'pytest',
                                  'selenium', 'cypress', 'postman', 'swagger', 'openapi', 'json', 'xml', 'yaml', 'csv',
                                  'jupyter', 'colab', 'anaconda', 'conda', 'pip', 'npm', 'yarn', 'maven', 'gradle',
                                  'scipy', 'statsmodels', 'xgboost', 'lightgbm', 'catboost', 'keras', 'hugging face',
                                  'bert', 'gpt', 'transformer', 'lstm', 'rnn', 'cnn', 'gan', 'reinforcement learning',
                                  'supervised learning', 'unsupervised learning', 'classification', 'regression', 'clustering',
                                  'time series', 'forecasting', 'optimization', 'ab testing', 'a/b testing', 'hypothesis testing',
                                  'statistical modeling', 'predictive modeling', 'data mining', 'data visualization',
                                  'business intelligence', 'bi', 'analytics', 'big data', 'streaming', 'batch processing',
                                  'api development', 'web development', 'frontend', 'backend', 'full stack', 'fullstack',
                                  'mobile development', 'ios', 'android', 'react native', 'flutter', 'xamarin',
                                  'cloud computing', 'cloud architecture', 'solution architecture', 'system design',
                                  'database design', 'data modeling', 'schema design', 'query optimization',
                                  'performance tuning', 'scalability', 'high availability', 'disaster recovery',
                                  'security', 'authentication', 'authorization', 'encryption', 'oauth', 'jwt',
                                  'version control', 'code review', 'unit testing', 'integration testing', 'testing',
                                  'debugging', 'troubleshooting', 'monitoring', 'logging', 'alerting', 'observability',
                                  'grafana', 'prometheus', 'elk', 'elasticsearch', 'logstash', 'kibana', 'splunk',
                                  'datadog', 'new relic', 'cloudwatch', 'azure monitor', 'google analytics',
                                  'seo', 'sem', 'digital marketing', 'crm', 'salesforce', 'hubspot', 'marketo',
                                  'product management', 'project management', 'stakeholder management', 'requirements gathering',
                                  'documentation', 'technical writing', 'presentation', 'communication', 'collaboration',
                                  'leadership', 'mentoring', 'training', 'coaching', 'team building', 'problem solving',
                                  'critical thinking', 'analytical skills', 'attention to detail', 'time management']
                    
                    # Action verbs (EXPANDED)
                    action_verbs = ['developed', 'managed', 'led', 'created', 'implemented', 'designed',
                                   'built', 'improved', 'increased', 'reduced', 'launched', 'delivered',
                                   'coordinated', 'analyzed', 'optimized', 'automated', 'established',
                                   'architected', 'engineered', 'deployed', 'maintained', 'migrated',
                                   'integrated', 'configured', 'administered', 'monitored', 'troubleshot',
                                   'debugged', 'refactored', 'enhanced', 'streamlined', 'standardized',
                                   'consolidated', 'modernized', 'transformed', 'revolutionized', 'pioneered',
                                   'spearheaded', 'initiated', 'founded', 'established', 'drove', 'accelerated',
                                   'scaled', 'expanded', 'grew', 'boosted', 'maximized', 'elevated',
                                   'strengthened', 'fortified', 'secured', 'protected', 'validated',
                                   'verified', 'tested', 'evaluated', 'assessed', 'audited', 'reviewed',
                                   'researched', 'investigated', 'identified', 'discovered', 'uncovered',
                                   'resolved', 'fixed', 'corrected', 'addressed', 'mitigated', 'prevented',
                                   'eliminated', 'minimized', 'decreased', 'lowered', 'cut', 'saved',
                                   'generated', 'produced', 'achieved', 'accomplished', 'executed', 'performed',
                                   'conducted', 'facilitated', 'orchestrated', 'supervised', 'oversaw',
                                   'directed', 'guided', 'mentored', 'trained', 'educated', 'coached',
                                   'advised', 'consulted', 'recommended', 'proposed', 'suggested', 'advocated',
                                   'presented', 'communicated', 'collaborated', 'partnered', 'liaised',
                                   'negotiated', 'influenced', 'persuaded', 'convinced', 'motivated',
                                   'inspired', 'empowered', 'enabled', 'supported', 'assisted', 'helped',
                                   'contributed', 'participated', 'engaged', 'volunteered', 'organized',
                                   'planned', 'strategized', 'forecasted', 'predicted', 'projected',
                                   'budgeted', 'allocated', 'distributed', 'prioritized', 'scheduled',
                                   'documented', 'recorded', 'reported', 'tracked', 'measured', 'quantified',
                                   'calculated', 'computed', 'processed', 'aggregated', 'synthesized',
                                   'compiled', 'collected', 'gathered', 'extracted', 'retrieved', 'queried',
                                   'filtered', 'sorted', 'organized', 'structured', 'formatted', 'normalized',
                                   'cleaned', 'validated', 'transformed', 'converted', 'migrated', 'imported',
                                   'exported', 'transferred', 'synchronized', 'integrated', 'connected',
                                   'linked', 'mapped', 'modeled', 'simulated', 'prototyped', 'demoed',
                                   'showcased', 'demonstrated', 'illustrated', 'visualized', 'charted',
                                   'graphed', 'plotted', 'rendered', 'published', 'released', 'shipped']
                    
                    # Calculate matches
                    keyword_matches = []
                    tech_skill_matches = []
                    phrase_matches = []
                    action_verb_matches = []
                    
                    for keyword in set(job_keywords):
                        if keyword in full_resume_text:
                            keyword_matches.append(keyword)
                            if keyword in tech_skills:
                                tech_skill_matches.append(keyword)
                    
                    for phrase in set(job_phrases):
                        if phrase in full_resume_text:
                            phrase_matches.append(phrase)
                    
                    for verb in action_verbs:
                        if verb in resume_text['experience']:
                            action_verb_matches.append(verb)
                    
                    # Calculate weighted scores (IMPROVED ALGORITHM)
                    # More generous scoring to help users reach 100%
                    
                    # Keywords score (40 points) - base + bonus
                    base_keyword_score = (len(keyword_matches) / max(len(set(job_keywords)), 1)) * 35
                    bonus_keywords = min(5, len(keyword_matches) // 10)  # Bonus for having many keywords
                    keyword_score = min(40, base_keyword_score + bonus_keywords)
                    
                    # Tech skills score (25 points) - weighted higher if tech job
                    tech_keywords_in_job = [k for k in set(job_keywords) if k in tech_skills]
                    if tech_keywords_in_job:
                        tech_score = (len(tech_skill_matches) / max(len(tech_keywords_in_job), 1)) * 25
                    else:
                        # If not a tech-heavy job, give partial credit
                        tech_score = (len(tech_skill_matches) / max(len(tech_skills[:20]), 1)) * 25
                    tech_score = min(25, tech_score)
                    
                    # Phrase score (20 points) - bonus for exact matches
                    unique_phrases = list(set(job_phrases))
                    base_phrase_score = (len(phrase_matches) / max(len(unique_phrases), 1)) * 18
                    bonus_phrases = min(2, len(phrase_matches) // 5)  # Bonus for many phrase matches
                    phrase_score = min(20, base_phrase_score + bonus_phrases)
                    
                    # Action verb score (10 points) - easier to max out
                    action_verb_score = min(10, (len(action_verb_matches) / 5) * 10)  # Need only 5 verbs for full score
                    
                    # Format score (5 points) - always full since we use good template
                    format_score = 5
                    
                    total_score = min(100, int(keyword_score + tech_score + phrase_score + action_verb_score + format_score))
                    
                    # Quality checks
                    has_quantifiable = bool(re.search(r'\d+%|\d+\+|increased|decreased|improved|reduced', resume_text['experience']))
                    has_email = bool(data.get('email'))
                    has_phone = bool(data.get('phone'))
                    contact_complete = has_email and has_phone
                    
                    # Smart Project Selection
                    st.markdown("---")
                    st.markdown("## üöÄ AI-Powered Project Selection")
                    st.info("Analyzing all 27 projects and selecting the top 5 that best match this job...")
                    
                    project_scores = []
                    for project in ALL_PROJECTS:
                        score = 0
                        project_text = f"{project['title']} {project['description']}".lower()
                        
                        # Match job keywords in project
                        for keyword in job_keywords:
                            if keyword in project_text:
                                score += 2
                        
                        # Bonus for project keywords matching job
                        for pk in project['keywords']:
                            if pk in job_desc_lower:
                                score += 5
                        
                        # Extra bonus for tech skills match
                        for tech in tech_skill_matches:
                            if tech in project_text:
                                score += 3
                        
                        project_scores.append((project, score))
                    
                    # Sort and select top 5
                    project_scores.sort(key=lambda x: x[1], reverse=True)
                    top_projects = [p[0] for p in project_scores[:5]]
                    st.session_state.selected_projects = top_projects
                    
                    # Update resume data with selected projects
                    st.session_state.resume_data['projects'] = top_projects
                    
                    st.success("‚úÖ Top 5 Projects Selected Based on Job Requirements!")
                    
                    for i, proj in enumerate(top_projects, 1):
                        relevance_score = project_scores[i-1][1]
                        with st.expander(f"üîπ Project {i}: {proj['title']} (Relevance: {relevance_score} points)", expanded=i<=2):
                            st.markdown(f"**Description:**")
                            st.write(proj['description'])
                            st.markdown(f"**Key Skills:** {', '.join(proj['keywords'])}")
                    
                    # ATS Score Display
                    st.markdown("---")
                    st.markdown("## üìä Comprehensive ATS Score Analysis")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Overall Score", f"{total_score}%", 
                                 delta="Excellent" if total_score >= 85 else "Strong" if total_score >= 70 else "Good" if total_score >= 60 else "Needs Work")
                    with col2:
                        st.metric("Keywords", f"{len(keyword_matches)}/{len(set(job_keywords))}")
                    with col3:
                        st.metric("Tech Skills", f"{len(tech_skill_matches)}")
                    with col4:
                        st.metric("Phrases", f"{len(phrase_matches)}")
                    
                    if total_score >= 85:
                        st.success("üèÜ **Outstanding Match!** You're in the top 10%. Your resume is perfectly optimized.")
                    elif total_score >= 70:
                        st.success("‚úÖ **Strong Match!** Your resume is highly competitive for this role.")
                    elif total_score >= 60:
                        st.warning("‚ö†Ô∏è **Good Match** - Solid foundation, but room for improvement exists.")
                    else:
                        st.error("‚ùå **Needs Improvement** - Add more relevant keywords and tailor your experience.")
                    
                    with st.expander("üìä Detailed Score Breakdown", expanded=True):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("#### Score Components")
                            st.progress(keyword_score / 40, text=f"Keywords: {int(keyword_score)}/40")
                            st.progress(tech_score / 25, text=f"Technical Skills: {int(tech_score)}/25")
                            st.progress(phrase_score / 20, text=f"Key Phrases: {int(phrase_score)}/20")
                            st.progress(action_verb_score / 10, text=f"Action Verbs: {int(action_verb_score)}/10")
                            st.progress(format_score / 5, text=f"Format: {int(format_score)}/5")
                        
                        with col2:
                            st.markdown("#### Quality Checks")
                            st.write("‚úÖ Contact Info Complete" if contact_complete else "‚ùå Add Contact Info")
                            st.write("‚úÖ Quantifiable Results" if has_quantifiable else "‚ö†Ô∏è Add Metrics/Numbers")
                            st.write(f"‚úÖ {len(action_verb_matches)} Action Verbs" if action_verb_matches else "‚ö†Ô∏è Use Action Verbs")
                            st.write(f"‚úÖ {len(tech_skill_matches)} Tech Skills" if tech_skill_matches else "‚ö†Ô∏è List Tech Skills")
                            st.write(f"‚úÖ {len(top_projects)} Relevant Projects")
                    
                    with st.expander("üîë Matched Keywords & Skills"):
                        if tech_skill_matches:
                            st.markdown("**üîß Technical Skills Found:**")
                            st.info(", ".join(sorted(set(tech_skill_matches))))
                        
                        if phrase_matches:
                            st.markdown("**üìù Key Phrases Found:**")
                            st.success(", ".join(list(set(phrase_matches))[:15]))
                        
                        if action_verb_matches:
                            st.markdown("**üí™ Action Verbs Used:**")
                            st.write(", ".join(sorted(set(action_verb_matches))))
                    
                    with st.expander("üí° Personalized Recommendations"):
                        missing_keywords = list(set(job_keywords) - set(keyword_matches))
                        missing_tech = [k for k in job_keywords if k in tech_skills and k not in tech_skill_matches]
                        
                        recommendations = []
                        
                        if missing_tech:
                            recommendations.append(f"**üîß Add Technical Skills:** {', '.join(missing_tech[:5])}")
                        
                        if missing_keywords and len(missing_keywords) > 5:
                            recommendations.append(f"**üéØ Include Keywords:** {', '.join(missing_keywords[:8])}")
                        
                        if not has_quantifiable:
                            recommendations.append("**üìä Add Metrics:** Include numbers (e.g., 'Increased efficiency by 30%', 'Processed 10,000+ records')")
                        
                        if len(action_verb_matches) < 5:
                            recommendations.append("**üí™ Use Action Verbs:** Start bullets with: Developed, Led, Implemented, Optimized, Delivered")
                        
                        if len(phrase_matches) < 5:
                            recommendations.append("**üìù Mirror Job Language:** Use exact phrases from the job description")
                        
                        if recommendations:
                            for i, rec in enumerate(recommendations, 1):
                                st.markdown(f"{i}. {rec}")
                        else:
                            st.success("‚ú® Excellent! Your resume is well-optimized. Consider minor tweaks for perfection.")
                    
                    st.markdown("---")
                    st.markdown("### üìà Industry Benchmark Comparison")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Your Score", f"{total_score}%")
                    with col2:
                        st.metric("Industry Average", "65%")
                    with col3:
                        st.metric("Top 10% Threshold", "85%+")
                    
                    if total_score >= 85:
                        st.balloons()
                        st.success("üèÜ **You're in the Top 10%!** Your resume stands out from the competition.")
                    elif total_score >= 65:
                        st.info("üìä **Above Average** - You're competitive. Keep refining for top tier!")
                    else:
                        st.warning("üìâ **Below Average** - Focus on keywords, skills, and tailoring to this specific role.")
            else:
                st.error("‚ö†Ô∏è Please paste a job description to analyze!")
    else:
        st.info("üëà Please fill your information in Tab 1 first.")

with tab3:
    st.header("‚ùì AI-Powered Interview Preparation")
    
    if st.session_state.resume_data and st.session_state.selected_projects:
        data = st.session_state.resume_data
        projects = st.session_state.selected_projects
        
        st.markdown("### Generate Personalized Interview Questions")
        st.info("Get the top 10 interview questions with detailed answers tailored to YOUR profile and the job you're applying for!")
        
        if st.button("üéØ Generate Interview Q&A", type="primary"):
            job_titles = [exp.get('title', '') for exp in data.get('experiences', [])]
            primary_role = job_titles[0] if job_titles else "Data Professional"
            skills_list = data.get('technical_skills', [])[:5]
            cert_name = "Professional Certificate in Artificial Intelligence from Bhartiya Vidya Bhavans Sardar Patel Institute Of Technology"
            
            with st.spinner("Generating personalized interview preparation..."):
                st.success("‚úÖ Your Personalized Interview Prep is Ready!")
                
                questions = [
                    {
                        "category": "Introduction",
                        "q": f"Tell me about yourself and your experience as a {primary_role}.",
                        "a": f"I'm a passionate {primary_role} with expertise in {', '.join(skills_list)}. {data.get('summary', '')} Throughout my career, I've completed {len(projects)} significant projects, including {projects[0]['title']}, where {projects[0]['description'][:120]}... I hold a {cert_name}, which has strengthened both my theoretical foundation and practical skills. I'm excited about applying my experience to drive results in this role.",
                        "tip": "Keep it to 2-3 minutes. Structure: Present ‚Üí Past experience ‚Üí Why you're interested in this role."
                    },
                    {
                        "category": "Strengths",
                        "q": f"What is your greatest strength as a {primary_role}?",
                        "a": f"My greatest strength is my ability to combine technical expertise with practical problem-solving. I'm proficient in {', '.join(skills_list)}, and I've demonstrated this through projects like {projects[0]['title']}, where I {projects[0]['description'][:100]}... This combination of technical depth and hands-on experience allows me to tackle complex challenges effectively and deliver measurable results.",
                        "tip": "Choose a strength relevant to the job. Back it up with a specific example and quantifiable results."
                    },
                    {
                        "category": "Project Experience",
                        "q": "Can you describe a challenging project you worked on and how you overcame obstacles?",
                        "a": f"One of my most challenging projects was {projects[1]['title'] if len(projects) > 1 else projects[0]['title']}. {projects[1]['description'] if len(projects) > 1 else projects[0]['description']} The main challenge was balancing efficiency with accuracy while working with complex data. I overcame this by breaking down the problem, applying {', '.join(projects[1]['keywords'][:3] if len(projects) > 1 else projects[0]['keywords'][:3])} techniques, and iterating based on results. The project taught me the importance of systematic problem-solving and continuous testing.",
                        "tip": "Use STAR method: Situation, Task, Action, Result. Emphasize what YOU did and the outcome."
                    },
                    {
                        "category": "Technical Skills",
                        "q": f"What technical skills make you a strong candidate for this {primary_role} position?",
                        "a": f"I bring a comprehensive technical toolkit including {', '.join(skills_list)}. I have hands-on experience with these across multiple projects: in {projects[0]['title']}, I applied {', '.join(projects[0]['keywords'][:2])}; in {projects[2]['title'] if len(projects) > 2 else projects[1]['title']}, I utilized {', '.join(projects[2]['keywords'][:2] if len(projects) > 2 else projects[1]['keywords'][:2])}. I'm also committed to continuous learning‚ÄîI recently completed {cert_name}. This combination of practical experience and formal training makes me well-prepared for the technical demands of this role.",
                        "tip": "Match your skills to the job requirements. Provide specific examples of when you used each skill."
                    },
                    {
                        "category": "Problem Solving",
                        "q": "How do you approach complex problem-solving in your work?",
                        "a": f"I follow a systematic approach: First, I thoroughly understand the requirements and define the problem clearly. Then, I break it down into manageable components. As demonstrated in {projects[2]['title'] if len(projects) > 2 else projects[0]['title']}, I {projects[2]['description'][:110] if len(projects) > 2 else projects[0]['description'][:110]}... I believe in iterative development, rigorous testing, and maintaining clean, well-documented code. I also collaborate with team members to get different perspectives and ensure the solution is robust and scalable.",
                        "tip": "Show your structured thinking. Mention collaboration and how you validate your solutions."
                    },
                    {
                        "category": "Data Experience",
                        "q": "Describe your experience working with data analysis and what methodologies you use.",
                        "a": f"I have extensive data experience through projects like {projects[3]['title'] if len(projects) > 3 else projects[1]['title']}. {projects[3]['description'][:130] if len(projects) > 3 else projects[1]['description'][:130]}... My approach involves: 1) Data collection and cleaning, 2) Exploratory analysis to understand patterns, 3) Applying appropriate statistical/ML techniques, 4) Validation and testing, 5) Clear visualization and communication of insights. I'm proficient with {', '.join([s for s in skills_list if 'pandas' in s.lower() or 'numpy' in s.lower() or 'python' in s.lower()][:3])}, which enables me to handle complex datasets efficiently.",
                        "tip": "Show your end-to-end data workflow. Emphasize both technical skills and business insights."
                    },
                    {
                        "category": "Python & Programming",
                        "q": "What's your experience with Python, and which libraries are you most comfortable with?",
                        "a": f"Python is my primary programming language, and I've used it extensively across {len(projects)} projects. I'm highly proficient in {', '.join([s for s in skills_list if 'python' in s.lower() or 'pandas' in s.lower() or 'numpy' in s.lower()][:4])}. For example, in {projects[4]['title'] if len(projects) > 4 else projects[0]['title']}, I {projects[4]['description'][:120] if len(projects) > 4 else projects[0]['description'][:120]}... I focus on writing clean, efficient, and maintainable code following PEP 8 standards and best practices.",
                        "tip": "Be specific about libraries and frameworks. Mention code quality and best practices."
                    },
                    {
                        "category": "Continuous Learning",
                        "q": "How do you stay current with technology trends and continue developing your skills?",
                        "a": f"I'm committed to continuous learning through multiple channels: 1) Formal education‚ÄîI completed {cert_name}, 2) Hands-on projects‚ÄîI've worked on diverse projects like {', '.join([p['title'][:40] for p in projects[:3]])}, 3) Online resources‚ÄîI follow industry blogs, research papers, and technical documentation, 4) Community engagement‚ÄîI participate in technical forums and GitHub repositories. I believe staying current is essential in our rapidly evolving field, and I dedicate time weekly to learning new tools and techniques.",
                        "tip": "Show you're proactive about learning. Mention specific resources or recent topics you've explored."
                    },
                    {
                        "category": "Machine Learning / AI",
                        "q": "Can you explain your experience with machine learning or AI technologies?",
                        "a": f"I have practical ML/AI experience through projects like {projects[-2]['title'] if len(projects) > 1 else projects[0]['title']} and {projects[-1]['title']}. {projects[-1]['description']} I understand the full ML workflow: data preprocessing, feature engineering, model selection, training, evaluation, and deployment. I've worked with algorithms including regression, classification, clustering, and neural networks. My {cert_name} has given me a strong theoretical foundation in AI concepts, which I've applied in real-world scenarios to solve business problems and generate actionable insights.",
                        "tip": "Cover both theory and practice. Mention specific algorithms and real outcomes."
                    },
                    {
                        "category": "Closing",
                        "q": "Why should we hire you for this position?",
                        "a": f"You should hire me because I offer a unique combination of proven technical skills, diverse project experience, and a growth mindset. My expertise in {', '.join(skills_list)} combined with hands-on experience in {len(projects)} projects‚Äîfrom {projects[0]['title']} to {projects[-1]['title']}‚Äîdemonstrates my ability to deliver results. I'm passionate about {primary_role.lower()} work, detail-oriented, and thrive in collaborative environments. My {cert_name} shows my commitment to professional development. I'm not just looking for a job; I'm looking to contribute meaningfully to your team's success and grow with the organization. I'm confident I can bring immediate value while continuing to learn and adapt.",
                        "tip": "Tie everything together. Show enthusiasm, mention cultural fit, and express genuine interest in the company."
                    }
                ]
                
                for i, qa in enumerate(questions, 1):
                    with st.expander(f"‚ùì Question {i} [{qa['category']}]: {qa['q']}", expanded=i<=2):
                        st.markdown("### üí¨ Your Answer:")
                        st.write(qa['a'])
                        st.markdown("---")
                        st.markdown("### üí° Interview Tip:")
                        st.info(qa['tip'])
                
                st.markdown("---")
                st.markdown("## üìö Complete Interview Preparation Guide")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("""
                    ### üìã Before the Interview
                    
                    - ‚úÖ **Research the company** (products, culture, recent news)
                    - ‚úÖ **Review all your projects** in detail
                    - ‚úÖ **Prepare questions** to ask interviewer
                    - ‚úÖ **Practice answers** out loud (record yourself!)
                    - ‚úÖ **Test tech setup** (if virtual interview)
                    - ‚úÖ **Print extra resumes** (if in-person)
                    - ‚úÖ **Plan your outfit** (professional attire)
                    - ‚úÖ **Get good sleep** the night before
                    """)
                with col2:
                    st.markdown("""
                    ### üíº During the Interview
                    
                    - üéØ **Be authentic** and confident
                    - üéØ **Use STAR method** for behavioral questions
                    - üéØ **Give specific examples** with numbers
                    - üéØ **Show enthusiasm** for the role
                    - üéØ **Ask thoughtful questions**
                    - üéØ **Take notes** during conversation
                    - üéØ **Thank the interviewer** at the end
                    - üéØ **Follow up** with thank-you email within 24hrs
                    """)
                
                st.markdown("### üé≠ Common Follow-up Questions to Prepare For:")
                st.markdown("""
                - "Tell me about a time you failed" ‚Üí Focus on what you learned
                - "Where do you see yourself in 5 years?" ‚Üí Show ambition + loyalty
                - "Why are you leaving your current role?" ‚Üí Stay positive
                - "What's your expected salary?" ‚Üí Have a range researched
                - "Do you have any questions for us?" ‚Üí ALWAYS have 3-5 prepared
                """)
                
                st.success("üéâ You're well-prepared! Review these answers, practice out loud, and go confidently into your interview!")
    else:
        st.info("üëà Please complete Tab 1 (Fill Information) and Tab 2 (ATS Analysis) first to generate interview questions.")

with tab4:
    st.header("üëÅÔ∏è Resume Preview & Download")
    
    if st.session_state.resume_data:
        data = st.session_state.resume_data
        
        # Convert photo to base64
        photo_base64 = ""
        if data.get('photo'):
            photo_base64 = base64.b64encode(data['photo']).decode()
        
        # Generate HTML
        resume_html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <style>
                body {{
                    font-family: Arial, Helvetica, sans-serif;
                    line-height: 1.6;
                    color: #333;
                    max-width: 850px;
                    margin: 0 auto;
                    padding: 20px;
                }}
                .header {{
                    text-align: center;
                    margin-bottom: 20px;
                }}
                .profile-photo {{
                    width: 120px;
                    height: 120px;
                    border-radius: 50%;
                    object-fit: cover;
                    margin: 0 auto 15px;
                    display: block;
                    border: 3px solid #2c3e50;
                }}
                h1 {{
                    font-size: 32px;
                    margin: 10px 0 5px 0;
                    color: #2c3e50;
                }}
                h2 {{
                    font-size: 18px;
                    border-bottom: 2px solid #2c3e50;
                    padding-bottom: 5px;
                    margin-top: 20px;
                    margin-bottom: 10px;
                    text-transform: uppercase;
                    color: #2c3e50;
                }}
                .contact {{
                    text-align: center;
                    margin-bottom: 20px;
                    font-size: 14px;
                    line-height: 1.8;
                }}
                .contact a {{
                    color: #2980b9;
                    text-decoration: none;
                    font-weight: 500;
                }}
                .contact a:hover {{
                    text-decoration: underline;
                }}
                
                /* Print styles - show full URLs */
                @media print {{
                    .contact a {{
                        color: #2980b9;
                        text-decoration: underline;
                    }}
                    .contact a:after {{
                        content: "";
                    }}
                }}
                .section {{
                    margin-bottom: 20px;
                }}
                .job, .edu, .project {{
                    margin-bottom: 15px;
                }}
                .job-header, .edu-header, .project-header {{
                    display: flex;
                    justify-content: space-between;
                    margin-bottom: 5px;
                }}
                .job-title, .degree, .project-name {{
                    font-weight: bold;
                    font-size: 16px;
                }}
                .company, .institution {{
                    font-style: italic;
                }}
                .date {{
                    color: #7f8c8d;
                    font-size: 14px;
                }}
                ul {{
                    margin: 5px 0;
                    padding-left: 20px;
                }}
                li {{
                    margin-bottom: 3px;
                }}
                .skills {{
                    display: flex;
                    flex-wrap: wrap;
                    gap: 5px;
                }}
                .skill {{
                    background: #ecf0f1;
                    padding: 5px 10px;
                    border-radius: 3px;
                    font-size: 14px;
                }}
                .project-desc {{
                    margin-top: 5px;
                    text-align: justify;
                }}
            </style>
        </head>
        <body>
            <div class="header">
                {f'<img src="data:image/png;base64,{photo_base64}" class="profile-photo">' if photo_base64 else ''}
                <h1>{data.get('name', 'Your Name')}</h1>
            </div>
            <div class="contact">
                {f"{data.get('location', '')}" if data.get('location') else ''}
                {f" | {data.get('phone', '')}" if data.get('phone') else ''}
                {f" | {data.get('email', '')}" if data.get('email') else ''}
                {f" | <a href='{data.get('linkedin')}' target='_blank'>{data.get('linkedin')}</a>" if data.get('linkedin') else ''}
                {f" | <a href='{data.get('github')}' target='_blank'>{data.get('github')}</a>" if data.get('github') else ''}
                {f" | <a href='{data.get('portfolio')}' target='_blank'>{data.get('portfolio')}</a>" if data.get('portfolio') else ''}
            </div>
            
            <div class="section">
                <h2>Professional Summary</h2>
                <p>{data.get('summary', '')}</p>
            </div>
        """
        
        if data.get('experiences'):
            resume_html += "<div class='section'><h2>Work Experience</h2>"
            for exp in data['experiences']:
                resume_html += f"""
                <div class="job">
                    <div class="job-header">
                        <div>
                            <div class="job-title">{exp['title']}</div>
                            <div class="company">{exp['company']}</div>
                        </div>
                        <div class="date">{exp['start']} - {exp['end']}</div>
                    </div>
                    <ul>
                """
                for resp in exp['responsibilities']:
                    if resp.strip():
                        resume_html += f"<li>{resp.strip()}</li>"
                resume_html += "</ul></div>"
            resume_html += "</div>"
        
        if data.get('projects') and len(data['projects']) > 0:
            resume_html += "<div class='section'><h2>Key Projects</h2>"
            for proj in data['projects']:
                resume_html += f"""
                <div class="project">
                    <div class="project-name">{proj['title']}</div>
                    <p class="project-desc">{proj['description']}</p>
                </div>
                """
            resume_html += "</div>"
        
        if data.get('education'):
            resume_html += "<div class='section'><h2>Education</h2>"
            for edu in data['education']:
                resume_html += f"""
                <div class="edu">
                    <div class="edu-header">
                        <div>
                            <div class="degree">{edu['degree']}</div>
                            <div class="institution">{edu['institution']}</div>
                        </div>
                        <div class="date">{edu['start']} - {edu['end']}</div>
                    </div>
                    {f"<div>GPA: {edu['gpa']}</div>" if edu.get('gpa') else ''}
                </div>
                """
            resume_html += "</div>"
        
        if data.get('technical_skills'):
            resume_html += "<div class='section'><h2>Technical Skills</h2><div class='skills'>"
            for skill in data['technical_skills']:
                resume_html += f"<span class='skill'>{skill}</span>"
            resume_html += "</div></div>"
        
        if data.get('certifications'):
            resume_html += "<div class='section'><h2>Certifications</h2><ul>"
            for cert in data['certifications']:
                resume_html += f"<li>{cert}</li>"
            resume_html += "</ul></div>"
        
        resume_html += "</body></html>"
        
        # Preview
        st.markdown("### üìÑ Your Professional Resume")
        st.components.v1.html(resume_html, height=800, scrolling=True)
        
        # Download
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="üì• Download Resume (HTML)",
                data=resume_html,
                file_name=f"{data.get('name', 'resume').replace(' ', '_')}_ATS_Resume.html",
                mime="text/html",
                type="primary"
            )
        with col2:
            st.info("üí° **To convert to PDF:** Open the HTML file in a browser, press Ctrl+P, and select 'Save as PDF'")
        
        if st.session_state.get('selected_projects'):
            st.success(f"‚úÖ Resume includes {len(st.session_state.selected_projects)} AI-selected projects optimized for your target role!")
    else:
        st.info("üëà Please complete Tab 1 (Fill Information) to generate your resume.")